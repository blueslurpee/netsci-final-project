{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60de1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import arrow\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd522dc",
   "metadata": {},
   "source": [
    "### Change here to select project output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26eda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = ['bayc', 'coolcats', 'cryptoadz', 'cyberkongz', 'hashmasks', 'mayc', 'meebits', 'mekaverse', 'svs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b31ad4",
   "metadata": {},
   "source": [
    "### Store base data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b33210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_data(project):\n",
    "    PATH_TO_DATA = './data/collated/' + project + '.csv'  # Change if needed\n",
    "    column_names = [\"row\", \"tx_hash\", \"token_address\", \"from_address\", \"to_address\", \"token_id\", \"blk_number\", \"blk_timestamp\", \"eth_value\"]\n",
    "    \n",
    "    df = pd.read_csv(PATH_TO_DATA, delimiter=',', skiprows=1, names=column_names)\n",
    "    \n",
    "    df[\"from_address\"] = df.from_address.apply(lambda x: x.strip())\n",
    "    df[\"to_address\"] = df.to_address.apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5f847",
   "metadata": {},
   "source": [
    "### Build time-based dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ba4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timed_data(df):\n",
    "    ZERO_ADDRESS = '0x0000000000000000000000000000000000000000'\n",
    "    column_names = [\"date\", \"days_since_mint\", \"from_address\", \"to_address\", \"token_id\", \"blk_number\", \"eth_value\"]\n",
    "    \n",
    "    df_time = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        blk_timestamp = row['blk_timestamp']\n",
    "        date = arrow.get(blk_timestamp).datetime\n",
    "\n",
    "        # Remove whitespace from address rows\n",
    "        from_address = row['from_address']\n",
    "        to_address = row['to_address']\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "        \n",
    "        # Get days since mint and place a dummy value that we reference below\n",
    "        if from_address == ZERO_ADDRESS:\n",
    "            days_since_mint = 0\n",
    "        else:\n",
    "            days_since_mint = 1\n",
    "            \n",
    "        df_time = df_time.append({\n",
    "            'date': date,\n",
    "            'days_since_mint': days_since_mint,\n",
    "            'from_address': from_address,\n",
    "            'to_address': to_address,\n",
    "            'token_id': token_id, \n",
    "            'blk_number': blk_number,\n",
    "            'eth_value': eth_value,\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    # Replace the dummy value by looking at the original mint date in the original dataframe\n",
    "    for index, row in df_time.iterrows():\n",
    "        days_since_mint = row['days_since_mint']\n",
    "        \n",
    "        if days_since_mint == 1:\n",
    "            from_address = row['from_address']\n",
    "            date_now = row['date']\n",
    "            \n",
    "            df_index = df.index[df['to_address'] == from_address]\n",
    "            date_mint = min(df_time.loc[df_index, 'date'])\n",
    "\n",
    "            date_diff = date_now - date_mint\n",
    "            date_diff = date_diff.days\n",
    "            \n",
    "            df_time.at[df_index,'days_since_mint'] = date_diff\n",
    "            \n",
    "    df_time['days_since_mint'] = df_time['days_since_mint'].fillna(0)\n",
    "    return df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5ece0",
   "metadata": {},
   "source": [
    "### Build graph objects from time base dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04a3c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_timed(df_time):    \n",
    "    # Building a network per block\n",
    "    # we will use a weighted and directed graph.\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    plot_interval = 24 * 3600 * 10 # 1 day\n",
    "    start_timestamp = df_time['date'].iloc[0]\n",
    "\n",
    "    # loop over the pandas dataframe.\n",
    "    for index, row in df_time.iterrows():\n",
    "\n",
    "        # read the values from the dataframe.\n",
    "        # token_id  blk_timestamp eth_value \n",
    "        date = row['date']\n",
    "        from_address = row['from_address']\n",
    "        to_address = row['to_address']\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "\n",
    "        # make sure both addresses are in the graph.\n",
    "        if from_address not in graph:\n",
    "            graph.add_node(from_address)\n",
    "        if to_address not in graph:\n",
    "            graph.add_node(to_address)\n",
    "\n",
    "        # lookup value of both nodes at the time of this block\n",
    "        # if (not from_address == '0x0000000000000000000000000000000000000000'):\n",
    "        #     address = w3.toChecksumAddress(from_address)\n",
    "        #     value_from = w3.eth.get_balance(address, block_identifier=block)\n",
    "        # if (not to_address == '0x0000000000000000000000000000000000000000'):\n",
    "        #     address = w3.toChecksumAddress(to_address)\n",
    "        #     value_to = w3.eth.get_balance(address, block_identifier=block)\n",
    "\n",
    "        # set the attributes on this node.\n",
    "        # TODO: replace dummy values\n",
    "        nx.set_node_attributes(graph, {from_address:100, to_address:100}, 'value')\n",
    "\n",
    "        # keep track of how many trades a wallet has done.\n",
    "        trades = nx.get_node_attributes(graph, \"trades\")\n",
    "        if from_address in trades:\n",
    "            nx.set_node_attributes(graph, {from_address:trades[from_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {from_address:1}, 'trades')\n",
    "        if to_address in trades:\n",
    "            nx.set_node_attributes(graph, {to_address:trades[to_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {to_address:1}, 'trades')\n",
    "\n",
    "        # check if this NFT has already been sold and if yes, remove the old sale.\n",
    "        # this might be a candidate for memoization - c.b.\n",
    "        remove_edges = []\n",
    "        for (u,v,d) in graph.edges.data():\n",
    "            if d['token_id'] == token_id:\n",
    "                remove_edges.append((u,v))\n",
    "            # we need to remove them in a seperate step, since otherwise we change the datastructure that we are iterating over.\n",
    "        for (u,v) in remove_edges:\n",
    "            graph.remove_edge(u,v)\n",
    "\n",
    "        # add an edge for the transaction.\n",
    "        # TODO this will be changed\n",
    "        value = eth_value  # currently we don't have weth value\n",
    "        graph.add_edge(from_address, to_address, weight=value, token_id=token_id) # keep track of token id by adding it to the edge.\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d94a32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 9/9 [49:10<00:00, 327.84s/it]\n"
     ]
    }
   ],
   "source": [
    "for project in tqdm(projects):\n",
    "    df_time = create_timed_data(create_base_data(project))\n",
    "    g_time = build_graph_from_timed(df_time)\n",
    "    \n",
    "    np.save(f\"./memory/{project}.npy\", df_time)\n",
    "    nx.write_gml(g_time, f\"./memory/{project}.gml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}