{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60de1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import arrow\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from coinbase.wallet.client import Client\n",
    "\n",
    "load_dotenv('.env')\n",
    "client = Client(os.environ['COINBASE_KEY'], os.environ['COINBASE_SECRET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb2719",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf662372",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_ETH_TO_USD = True  # Should be True for first run, thereafter can be set to False\n",
    "TEST_LIMIT = None # Set to None for production run\n",
    "\n",
    "projects = [\n",
    "#     'bayc',\n",
    "#     'coolcats',\n",
    "#     'cryptoadz',\n",
    "#     'cyberkongz',\n",
    "#     'hashmasks',\n",
    "#     'mayc',\n",
    "#     'meebits',\n",
    "#     'mekaverse',\n",
    "#     'svs'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b31ad4",
   "metadata": {},
   "source": [
    "### Store base data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39b33210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_data(project):\n",
    "    PATH_TO_DATA = './data/collated/' + project + '.csv'  # Change if needed\n",
    "    column_names = [\"row\", \"tx_hash\", \"token_address\", \"from_address\", \"to_address\", \"token_id\", \"blk_number\", \"blk_timestamp\", \"eth_value\"]\n",
    "    \n",
    "    df = pd.read_csv(PATH_TO_DATA, delimiter=',', skiprows=1, names=column_names)\n",
    "    \n",
    "    df[\"from_address\"] = df.from_address.apply(lambda x: x.strip())\n",
    "    df[\"to_address\"] = df.to_address.apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae960b",
   "metadata": {},
   "source": [
    "### Transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e24dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transaction_data(project):\n",
    "    PATH_TO_DATA = f\"./data/balances/{project}.csv\"\n",
    "    return pd.read_csv(PATH_TO_DATA)\n",
    "\n",
    "errors = []\n",
    "\n",
    "def lookup_transaction_value(df, block, account):\n",
    "    value = 0\n",
    "    \n",
    "    if account == '0x0000000000000000000000000000000000000000':\n",
    "        return value\n",
    "    \n",
    "    try:\n",
    "        b = df[(df['block'] == block) & (df['address'] == account)]\n",
    "        value = b['eth_value'].head(1).iat[0]\n",
    "    except Exception as e:\n",
    "        errors.append((block, account))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde2182",
   "metadata": {},
   "source": [
    "### Setup ETH/USD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36aaa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eth_to_usd_lookup():\n",
    "    \"\"\"The result is what one ETH is worth in USD\"\"\"\n",
    "    column_names = [\"date\", \"eth_to_usd\"]\n",
    "    df_eth_to_usd = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    for project in projects:\n",
    "        df_transactions = get_transaction_data(project)\n",
    "        \n",
    "        df_transactions['eth_value'] = df_transactions['eth_value'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df_transactions['usd_value'] = df_transactions['usd_value'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        \n",
    "        df_transactions = df_transactions.astype({\n",
    "            'eth_value': 'float64',\n",
    "            'usd_value': 'float64'\n",
    "        })\n",
    "        \n",
    "        df_transactions = df_transactions[df_transactions['eth_value'] != 0].groupby('date', as_index=False).first()\n",
    "    \n",
    "        for index, row in tqdm(df_transactions.iterrows(), total=df_transactions.shape[0]):\n",
    "            date = row['date']\n",
    "            eth_to_usd = row['usd_value'] / row['eth_value']\n",
    "\n",
    "            df_eth_to_usd = df_eth_to_usd.append({\n",
    "                'date': date,\n",
    "                'eth_to_usd': eth_to_usd,\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "    df_eth_to_usd = df_eth_to_usd.groupby('date', as_index=False).first()\n",
    "    print(df_eth_to_usd)\n",
    "    np.save(f\"./memory/eth_to_usd.npy\", df_eth_to_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aa9ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 51/51 [00:00<00:00, 1135.41it/s]\n",
      "100%|█████████████████████████████████████████| 85/85 [00:00<00:00, 1155.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  eth_to_usd\n",
      "0   2021-09-09     3499.54\n",
      "1   2021-09-10     3424.32\n",
      "2   2021-09-11     3209.29\n",
      "3   2021-09-12     3266.97\n",
      "4   2021-09-13     3403.81\n",
      "..         ...         ...\n",
      "80  2021-11-28     4098.53\n",
      "81  2021-11-29     4298.38\n",
      "82  2021-11-30     4449.42\n",
      "83  2021-12-01     4636.43\n",
      "84  2021-12-02     4586.87\n",
      "\n",
      "[85 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if SETUP_ETH_TO_USD:\n",
    "    build_eth_to_usd_lookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb971bca",
   "metadata": {},
   "source": [
    "### Helper function to get eth_to_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bb463f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.load('./memory/eth_to_usd.npy', allow_pickle=True)\n",
    "df_eth_to_usd = pd.DataFrame(data=np_data, columns=['date', 'eth_to_usd'])\n",
    "\n",
    "def get_eth_to_usd(date):\n",
    "    # This is when you miss static types.. \n",
    "    date = date.strftime(\"%Y-%m-%d\")\n",
    "    rate = df_eth_to_usd.loc[df_eth_to_usd['date'] == date].eth_to_usd.values[0]\n",
    "    return rate\n",
    "\n",
    "# Convert ETH value to USD at specified date\n",
    "def get_usd_value(date, eth_value):\n",
    "    if eth_value == 0:\n",
    "        return eth_value\n",
    "    try:\n",
    "        rate = get_eth_to_usd(date)\n",
    "        return rate * eth_value\n",
    "    except IndexError:\n",
    "        print(\"Date not in values: \" + str(date))\n",
    "        return float(client.get_spot_price(currency_pair='ETH-USD', date=date)['amount']) * eth_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5f847",
   "metadata": {},
   "source": [
    "### Build time-based dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0ba4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timed_data(df, df_transactions):\n",
    "    ZERO_ADDRESS = '0x0000000000000000000000000000000000000000'\n",
    "    column_names = [\n",
    "        \"date\", \n",
    "        \"days_since_mint\", \n",
    "        \"from_address\", \n",
    "        \"to_address\", \n",
    "        \"token_id\", \n",
    "        \"blk_number\", \n",
    "        \"eth_value\",\n",
    "        \"usd_value\",\n",
    "        \"from_value\",\n",
    "        \"to_value\",\n",
    "        \"from_value_usd\",\n",
    "        \"to_value_usd\"\n",
    "    ]\n",
    "    \n",
    "    df_time = pd.DataFrame(columns=column_names)\n",
    "    df_total = df.shape[0]\n",
    "    \n",
    "    if TEST_LIMIT:\n",
    "        df = df.head(TEST_LIMIT)\n",
    "        \n",
    "    mint_date_set = False\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=df_total):\n",
    "        blk_timestamp = row['blk_timestamp']\n",
    "        date = arrow.get(blk_timestamp).datetime\n",
    "\n",
    "        from_address = str(row['from_address'])\n",
    "        to_address = str(row['to_address'])\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "        usd_value = get_usd_value(date, eth_value)\n",
    "        \n",
    "        if not mint_date_set:\n",
    "            days_since_mint = 0\n",
    "            mint_date = date\n",
    "            mint_date_set = True\n",
    "        else:\n",
    "            days_since_mint = (date - mint_date).days\n",
    "            \n",
    "        from_value = lookup_transaction_value(df_transactions, blk_number, from_address)\n",
    "        to_value = lookup_transaction_value(df_transactions, blk_number, to_address)\n",
    "        \n",
    "        from_value_usd = get_usd_value(date, from_value)\n",
    "        to_value_usd = get_usd_value(date, to_value)\n",
    "            \n",
    "        df_time = df_time.append({\n",
    "            'date': date,\n",
    "            'days_since_mint': days_since_mint,\n",
    "            'from_address': from_address,\n",
    "            'to_address': to_address,\n",
    "            'token_id': token_id, \n",
    "            'blk_number': blk_number,\n",
    "            'eth_value': eth_value,\n",
    "            'usd_value': usd_value,\n",
    "            'from_value': from_value,\n",
    "            'to_value': to_value,\n",
    "            'from_value_usd': from_value_usd,\n",
    "            'to_value_usd': to_value_usd,\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    df_time = df_time.infer_objects()\n",
    "    return df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5ece0",
   "metadata": {},
   "source": [
    "### Build graph objects from time base dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04a3c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_timed(df_time):    \n",
    "    # Building a network per block\n",
    "    # we will use a weighted and directed graph.\n",
    "    graph = nx.MultiDiGraph()\n",
    "\n",
    "    # loop over the pandas dataframe.\n",
    "    for index, row in tqdm(df_time.iterrows(), total=df_time.shape[0]):\n",
    "        # read the values from the dataframe.\n",
    "        # token_id  blk_timestamp eth_value \n",
    "        date = row['date']\n",
    "        from_address = row['from_address']\n",
    "        to_address = row['to_address']\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "        usd_value = row['usd_value']\n",
    "        from_value = row['from_value']\n",
    "        to_value = row['to_value']\n",
    "        from_value_usd = row['from_value_usd']\n",
    "        to_value_usd = row['to_value_usd']\n",
    "        \n",
    "        # make sure both addresses are in the graph.\n",
    "        if from_address not in graph:\n",
    "            graph.add_node(from_address)\n",
    "        if to_address not in graph:\n",
    "            graph.add_node(to_address)\n",
    "\n",
    "        # set the attributes on this node.\n",
    "        nx.set_node_attributes(graph, {from_address: from_value, to_address: to_value}, 'eth_value')\n",
    "        nx.set_node_attributes(graph, {from_address: from_value_usd, to_address: to_value_usd}, 'usd_value')\n",
    "\n",
    "        # keep track of how many trades a wallet has done.\n",
    "        trades = nx.get_node_attributes(graph, \"trades\")\n",
    "        if from_address in trades:\n",
    "            nx.set_node_attributes(graph, {from_address:trades[from_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {from_address:1}, 'trades')\n",
    "        if to_address in trades:\n",
    "            nx.set_node_attributes(graph, {to_address:trades[to_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {to_address:1}, 'trades')\n",
    "\n",
    "        # check if this NFT has already been sold and if yes, remove the old sale.\n",
    "        # this might be a candidate for memoization - c.b.\n",
    "        remove_edges = []\n",
    "        for (u,v,d) in graph.edges.data():\n",
    "            if d['token_id'] == token_id:\n",
    "                remove_edges.append((u,v))\n",
    "        # we need to remove them in a seperate step, since otherwise we change the datastructure that we are iterating over.\n",
    "        for (u,v) in remove_edges:\n",
    "            graph.remove_edge(u,v)\n",
    "\n",
    "        # add an edge for the transaction. # Note changed to usd_value\n",
    "        graph.add_edge(from_address, to_address, weight=usd_value, token_id=token_id) # keep track of token id by adding it to the edge.\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb9375",
   "metadata": {},
   "source": [
    "### Build time-based snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38d51e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snapshots(df_time):\n",
    "    res = {}\n",
    "    column_names = [\n",
    "        \"time_bucket\", \n",
    "        \"time_bucket_label\",\n",
    "        \"number_of_nodes\", \n",
    "        \"avg_clustering\", \n",
    "        \"reciprocity\", \n",
    "        \"assortativity\", \n",
    "        \"assortativity_base\", \n",
    "        \"assortativity_out_out\", \n",
    "        \"assortativity_in_in\", \n",
    "        \"assortativity_in_out\",\n",
    "        \"centrality_degree\",\n",
    "        \"centrality_closeness\", \n",
    "        \"centrality_betweenness\",\n",
    "        \"centrality_eigenvector\",\n",
    "        \"avg_clustering_random\",\n",
    "        \"assortativity_random\"\n",
    "    ]\n",
    "    \n",
    "    df_snapshots = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    df_time['date_quantile'], bins = pd.qcut(df_time['date'], 10, labels=False, retbins=True)\n",
    "    time_buckets = np.unique(df_time[\"date_quantile\"].to_numpy())\n",
    "    \n",
    "    for time_bucket, label in zip(time_buckets, bins):\n",
    "        selection = df_time[(df_time['date_quantile'] <= time_bucket)]\n",
    "        graph_snapshot = build_graph_from_timed(selection)\n",
    "        \n",
    "        res[label] = graph_snapshot\n",
    "        df_snapshots = df_snapshots.append({\n",
    "            \"time_bucket\": time_bucket,\n",
    "            \"time_bucket_label\": label,\n",
    "            \"number_of_nodes\": graph_snapshot.number_of_nodes(),\n",
    "            \"reciprocity\": nx.reciprocity(graph_snapshot),\n",
    "            \"assortativity\": nx.degree_assortativity_coefficient(graph_snapshot),\n",
    "            \"assortativity_base\": nx.degree_pearson_correlation_coefficient(graph_snapshot.to_undirected(), weight='weight'),\n",
    "            \"assortativity_out_out\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='out', y='out', weight='weight'),\n",
    "            \"assortativity_in_in\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='in', y='in', weight='weight'),\n",
    "            \"assortativity_in_out\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='in', y='out', weight='weight'),\n",
    "            \"centrality_degree\": nx.degree_centrality(graph_snapshot),\n",
    "            \"centrality_closeness\": nx.closeness_centrality(graph_snapshot),\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return (df_snapshots.sort_values(by=['time_bucket']), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d94a32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 22262/22262 [02:35<00:00, 143.28it/s]\n",
      "100%|█████████████████████████████████████| 34043/34043 [07:42<00:00, 73.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for project in projects:\n",
    "    df_transactions = get_transaction_data(project)\n",
    "    df_time = create_timed_data(create_base_data(project), df_transactions)\n",
    "    \n",
    "    np.save(f\"./memory/{project}/full.npy\", df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10156e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2302/2302 [00:01<00:00, 1435.90it/s]\n",
      "100%|██████████████████████████████████████| 4483/4483 [00:05<00:00, 751.69it/s]\n",
      "100%|██████████████████████████████████████| 6688/6688 [00:15<00:00, 426.77it/s]\n",
      "100%|██████████████████████████████████████| 8923/8923 [00:24<00:00, 358.19it/s]\n",
      "100%|████████████████████████████████████| 11136/11136 [00:39<00:00, 280.07it/s]\n",
      "100%|████████████████████████████████████| 13357/13357 [00:57<00:00, 233.60it/s]\n",
      "100%|████████████████████████████████████| 15583/15583 [01:18<00:00, 198.25it/s]\n",
      "100%|████████████████████████████████████| 17809/17809 [01:44<00:00, 170.13it/s]\n",
      "100%|████████████████████████████████████| 20100/20100 [02:16<00:00, 147.26it/s]\n",
      "100%|████████████████████████████████████| 22262/22262 [02:40<00:00, 138.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3420/3420 [00:03<00:00, 1125.17it/s]\n",
      "100%|██████████████████████████████████████| 6858/6858 [00:13<00:00, 523.91it/s]\n",
      "100%|████████████████████████████████████| 10220/10220 [00:30<00:00, 336.60it/s]\n",
      "100%|████████████████████████████████████| 13617/13617 [00:55<00:00, 244.89it/s]\n",
      "100%|████████████████████████████████████| 17022/17022 [01:26<00:00, 197.39it/s]\n",
      "100%|████████████████████████████████████| 20426/20426 [01:55<00:00, 176.75it/s]\n",
      "100%|████████████████████████████████████| 23830/23830 [02:30<00:00, 158.29it/s]\n",
      "100%|████████████████████████████████████| 27235/27235 [03:04<00:00, 147.62it/s]\n",
      "100%|████████████████████████████████████| 30638/30638 [03:44<00:00, 136.68it/s]\n",
      "100%|████████████████████████████████████| 34043/34043 [04:17<00:00, 132.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    }
   ],
   "source": [
    "for project in projects:\n",
    "    column_names = [\n",
    "        \"date\", \n",
    "        \"days_since_mint\", \n",
    "        \"from_address\", \n",
    "        \"to_address\", \n",
    "        \"token_id\", \n",
    "        \"blk_number\", \n",
    "        \"eth_value\",\n",
    "        \"usd_value\",\n",
    "        \"from_value\", \n",
    "        \"to_value\",\n",
    "        \"from_value_usd\",\n",
    "        \"to_value_usd\"\n",
    "    ]\n",
    "    \n",
    "    np_data = np.load(f\"./memory/{project}/full.npy\", allow_pickle=True)\n",
    "    df_time = pd.DataFrame(data=np_data, columns=column_names)\n",
    "    \n",
    "    df_snapshot_summary, g_snapshots = build_snapshots(df_time)\n",
    "    \n",
    "    for i, snapshot in enumerate(g_snapshots.keys()):\n",
    "        nx.write_gml(g_snapshots[snapshot], f\"./memory/{project}/snapshots/{i}.gml\")\n",
    "        print(\"Successfully wrote snapshot\")\n",
    "    \n",
    "    np.save(f\"./memory/{project}/snapshots/summary.npy\", df_snapshot_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}