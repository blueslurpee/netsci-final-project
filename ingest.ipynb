{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60de1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import arrow\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from coinbase.wallet.client import Client\n",
    "\n",
    "load_dotenv('.env')\n",
    "client = Client(os.environ['COINBASE_KEY'], os.environ['COINBASE_SECRET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb2719",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf662372",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_ETH_TO_USD = True  # Should be True for first run, thereafter can be set to False\n",
    "TEST_LIMIT = None # Set to None for production run\n",
    "\n",
    "projects = [\n",
    "    'bayc',\n",
    "    'coolcats',\n",
    "    'cryptoadz',\n",
    "    'cyberkongz',\n",
    "    'hashmasks',\n",
    "    'mayc',\n",
    "    'meebits',\n",
    "    'mekaverse',\n",
    "    'svs'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b31ad4",
   "metadata": {},
   "source": [
    "### Store base data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b33210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_data(project):\n",
    "    PATH_TO_DATA = './data/collated/' + project + '.csv'  # Change if needed\n",
    "    column_names = [\"row\", \"tx_hash\", \"token_address\", \"from_address\", \"to_address\", \"token_id\", \"blk_number\", \"blk_timestamp\", \"eth_value\"]\n",
    "    \n",
    "    df = pd.read_csv(PATH_TO_DATA, delimiter=',', skiprows=1, names=column_names)\n",
    "    \n",
    "    df[\"from_address\"] = df.from_address.apply(lambda x: x.strip())\n",
    "    df[\"to_address\"] = df.to_address.apply(lambda x: x.strip())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae960b",
   "metadata": {},
   "source": [
    "### Transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e24dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transaction_data(project):\n",
    "    PATH_TO_DATA = f\"./data/balances/{project}.csv\"\n",
    "    return pd.read_csv(PATH_TO_DATA)\n",
    "\n",
    "errors = []\n",
    "\n",
    "def lookup_account_value(df, block, account):\n",
    "    value = 0\n",
    "    df = df.infer_objects()\n",
    "    \n",
    "    if account == '0x0000000000000000000000000000000000000000':\n",
    "        return value\n",
    "    \n",
    "    try:\n",
    "        df_blocked = df[(df['block'] == block) & (df['address'] == account)]\n",
    "        value = df_blocked['eth_value'].head(1).iat[0]\n",
    "    except Exception as e:\n",
    "        errors.append((block, account))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde2182",
   "metadata": {},
   "source": [
    "### Setup ETH/USD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aaa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eth_to_usd_lookup():\n",
    "    \"\"\"The result is what one ETH is worth in USD\"\"\"\n",
    "    column_names = [\"date\", \"eth_to_usd\"]\n",
    "    df_eth_to_usd = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    for project in projects:\n",
    "        df_transactions = get_transaction_data(project)\n",
    "        \n",
    "        df_transactions['eth_value'] = df_transactions['eth_value'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        df_transactions['usd_value'] = df_transactions['usd_value'].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "        \n",
    "        df_transactions = df_transactions.astype({\n",
    "            'eth_value': 'float64',\n",
    "            'usd_value': 'float64'\n",
    "        })\n",
    "        \n",
    "        df_transactions = df_transactions[df_transactions['eth_value'] != 0].groupby('date', as_index=False).first()\n",
    "    \n",
    "        for index, row in tqdm(df_transactions.iterrows(), total=df_transactions.shape[0]):\n",
    "            date = row['date']\n",
    "            eth_to_usd = row['usd_value'] / row['eth_value']\n",
    "\n",
    "            df_eth_to_usd = df_eth_to_usd.append({\n",
    "                'date': date,\n",
    "                'eth_to_usd': eth_to_usd,\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "    df_eth_to_usd = df_eth_to_usd.groupby('date', as_index=False).first()\n",
    "    print(df_eth_to_usd)\n",
    "    \n",
    "    np.save(f\"./memory/eth_to_usd.npy\", df_eth_to_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa9ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 85/85 [00:00<00:00, 1067.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  eth_to_usd\n",
      "0   2021-09-09     3499.54\n",
      "1   2021-09-10     3424.32\n",
      "2   2021-09-11     3209.29\n",
      "3   2021-09-12     3266.97\n",
      "4   2021-09-13     3403.81\n",
      "..         ...         ...\n",
      "80  2021-11-28     4098.53\n",
      "81  2021-11-29     4298.38\n",
      "82  2021-11-30     4449.42\n",
      "83  2021-12-01     4636.43\n",
      "84  2021-12-02     4586.87\n",
      "\n",
      "[85 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if SETUP_ETH_TO_USD:\n",
    "    build_eth_to_usd_lookup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb971bca",
   "metadata": {},
   "source": [
    "### Helper function to get eth_to_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb463f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.load('./memory/eth_to_usd.npy', allow_pickle=True)\n",
    "df_eth_to_usd = pd.DataFrame(data=np_data, columns=['date', 'eth_to_usd'])\n",
    "\n",
    "def get_eth_to_usd(date):\n",
    "    # This is when you miss static types.. \n",
    "    date = date.strftime(\"%Y-%m-%d\")\n",
    "    rate = df_eth_to_usd.loc[df_eth_to_usd['date'] == date].eth_to_usd.values[0]\n",
    "    return rate\n",
    "\n",
    "# Convert ETH value to USD at specified date\n",
    "def get_usd_value(date, eth_value):\n",
    "    if eth_value == 0:\n",
    "        return eth_value\n",
    "    try:\n",
    "        rate = get_eth_to_usd(date)\n",
    "        return rate * eth_value\n",
    "    except IndexError:\n",
    "        print(\"Date not in values: \" + str(date))\n",
    "        return float(client.get_spot_price(currency_pair='ETH-USD', date=date)['amount']) * eth_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5f847",
   "metadata": {},
   "source": [
    "### Build time-based dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ba4159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timed_data(df, df_transactions):\n",
    "    ZERO_ADDRESS = '0x0000000000000000000000000000000000000000'\n",
    "    column_names = [\n",
    "        \"date\", \n",
    "        \"days_since_mint\", \n",
    "        \"from_address\", \n",
    "        \"to_address\", \n",
    "        \"token_id\", \n",
    "        \"blk_number\", \n",
    "        \"eth_value\",\n",
    "        \"usd_value\",\n",
    "        \"from_value\",\n",
    "        \"to_value\",\n",
    "        \"from_value_usd\",\n",
    "        \"to_value_usd\"\n",
    "    ]\n",
    "    \n",
    "    df_time = pd.DataFrame(columns=column_names)\n",
    "    df_total = df.shape[0]\n",
    "    \n",
    "    if TEST_LIMIT:\n",
    "        df = df.head(TEST_LIMIT)\n",
    "        \n",
    "    mint_date_set = False\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows(), total=df_total):\n",
    "        blk_timestamp = row['blk_timestamp']\n",
    "        date = arrow.get(blk_timestamp).datetime\n",
    "\n",
    "        from_address = str(row['from_address'])\n",
    "        to_address = str(row['to_address'])\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "        usd_value = get_usd_value(date, eth_value)\n",
    "        \n",
    "        if not mint_date_set:\n",
    "            days_since_mint = 0\n",
    "            mint_date = date\n",
    "            mint_date_set = True\n",
    "        else:\n",
    "            days_since_mint = (date - mint_date).days\n",
    "            \n",
    "        from_value = lookup_account_value(df_transactions, blk_number, from_address)\n",
    "        to_value = lookup_account_value(df_transactions, blk_number, to_address)\n",
    "        \n",
    "        from_value_usd = get_usd_value(date, from_value)\n",
    "        to_value_usd = get_usd_value(date, to_value)\n",
    "            \n",
    "        df_time = df_time.append({\n",
    "            'date': date,\n",
    "            'days_since_mint': days_since_mint,\n",
    "            'from_address': from_address,\n",
    "            'to_address': to_address,\n",
    "            'token_id': token_id, \n",
    "            'blk_number': blk_number,\n",
    "            'eth_value': eth_value,\n",
    "            'usd_value': usd_value,\n",
    "            'from_value': from_value,\n",
    "            'to_value': to_value,\n",
    "            'from_value_usd': from_value_usd,\n",
    "            'to_value_usd': to_value_usd,\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    df_time = df_time.infer_objects()\n",
    "    return df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97823b",
   "metadata": {},
   "source": [
    "### Driver code - saves a checkpoint to de-couple from next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d94a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    df_transactions = get_transaction_data(project)\n",
    "    df_time = create_timed_data(create_base_data(project), df_transactions)\n",
    "    \n",
    "    np.save(f\"./memory/{project}/full.npy\", df_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5ece0",
   "metadata": {},
   "source": [
    "### Build graph objects from time base dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a3c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_timed(df_time, old_graph=None):    \n",
    "    # Building a network per block\n",
    "    # we will use a weighted and directed graph.\n",
    "    graph = old_graph if old_graph is not None else nx.MultiDiGraph()\n",
    "\n",
    "    # loop over the pandas dataframe.\n",
    "    for index, row in tqdm(df_time.iterrows(), total=df_time.shape[0]):\n",
    "        # read the values from the dataframe.\n",
    "        # token_id  blk_timestamp eth_value \n",
    "        date = row['date']\n",
    "        from_address = row['from_address']\n",
    "        to_address = row['to_address']\n",
    "        token_id = row['token_id']\n",
    "        blk_number = row['blk_number']\n",
    "        eth_value = row['eth_value']\n",
    "        usd_value = row['usd_value']\n",
    "        from_value = row['from_value']\n",
    "        to_value = row['to_value']\n",
    "        from_value_usd = row['from_value_usd']\n",
    "        to_value_usd = row['to_value_usd']\n",
    "        \n",
    "        # make sure both addresses are in the graph.\n",
    "        if from_address not in graph:\n",
    "            graph.add_node(from_address)\n",
    "        if to_address not in graph:\n",
    "            graph.add_node(to_address)\n",
    "\n",
    "        # set the attributes on this node.\n",
    "        nx.set_node_attributes(graph, {from_address: from_value, to_address: to_value}, 'eth_value')\n",
    "        nx.set_node_attributes(graph, {from_address: from_value_usd, to_address: to_value_usd}, 'usd_value')\n",
    "\n",
    "        # keep track of how many trades a wallet has done.\n",
    "        trades = nx.get_node_attributes(graph, \"trades\")\n",
    "        if from_address in trades:\n",
    "            nx.set_node_attributes(graph, {from_address:trades[from_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {from_address:1}, 'trades')\n",
    "        if to_address in trades:\n",
    "            nx.set_node_attributes(graph, {to_address:trades[to_address] + 1}, 'trades')\n",
    "        else:\n",
    "            nx.set_node_attributes(graph, {to_address:1}, 'trades')\n",
    "\n",
    "        # add an edge for the transaction. # Note changed to usd_value\n",
    "        graph.add_edge(from_address, to_address, weight=usd_value, token_id=token_id) # keep track of token id by adding it to the edge.\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb9375",
   "metadata": {},
   "source": [
    "### Build time-based snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38d51e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snapshots(df_time):\n",
    "    res = []\n",
    "    column_names = [\n",
    "        \"time_bucket\", \n",
    "        \"time_bucket_label\",\n",
    "        \"number_of_nodes\",\n",
    "        \"degree\",\n",
    "        \"density\",\n",
    "        \"reciprocity\", \n",
    "        \"assortativity\", \n",
    "        \"assortativity_base\", \n",
    "        \"assortativity_out_out\", \n",
    "        \"assortativity_in_in\", \n",
    "        \"assortativity_in_out\",\n",
    "        \"centrality_degree\",\n",
    "        \"centrality_closeness\", \n",
    "    ]\n",
    "    \n",
    "    df_snapshots = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    df_time['date_quantile'], bins = pd.qcut(df_time['date'], 10, labels=False, retbins=True)\n",
    "    time_buckets = np.unique(df_time[\"date_quantile\"].to_numpy())\n",
    "    \n",
    "    for i, (time_bucket, label) in enumerate(zip(time_buckets, bins)):\n",
    "        graph_selection = df_time[(df_time['date_quantile'] == time_bucket)]\n",
    "        \n",
    "        if i != 0:\n",
    "            old_graph = res[i-1]\n",
    "        else:\n",
    "            old_graph = None\n",
    "        \n",
    "        graph_snapshot = build_graph_from_timed(graph_selection, old_graph=old_graph)\n",
    "        degree = [(node, val) for (node, val) in graph_snapshot.degree()]  # This is necesssary because .degree() returns a *VIEW*\n",
    "        \n",
    "        res.append(graph_snapshot)\n",
    "        df_snapshots = df_snapshots.append({\n",
    "            \"time_bucket\": time_bucket,\n",
    "            \"time_bucket_label\": label,\n",
    "            \"number_of_nodes\": graph_snapshot.number_of_nodes(),\n",
    "            \"degree\": degree,\n",
    "            \"density\": nx.density(graph_snapshot),\n",
    "            \"reciprocity\": nx.reciprocity(graph_snapshot),\n",
    "            \"assortativity\": nx.degree_assortativity_coefficient(graph_snapshot),\n",
    "            \"assortativity_base\": nx.degree_pearson_correlation_coefficient(graph_snapshot.to_undirected(), weight='weight'),\n",
    "            \"assortativity_out_out\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='out', y='out', weight='weight'),\n",
    "            \"assortativity_in_in\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='in', y='in', weight='weight'),\n",
    "            \"assortativity_in_out\": nx.degree_pearson_correlation_coefficient(graph_snapshot, x='in', y='out', weight='weight'),\n",
    "            \"centrality_degree\": nx.degree_centrality(graph_snapshot),\n",
    "            \"centrality_closeness\": nx.closeness_centrality(graph_snapshot),\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "    return (df_snapshots.sort_values(by=['time_bucket']), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10156e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5099/5099 [00:00<00:00, 5122.43it/s]\n",
      "100%|█████████████████████████████████████| 5126/5126 [00:01<00:00, 3176.86it/s]\n",
      "100%|█████████████████████████████████████| 5060/5060 [00:03<00:00, 1628.93it/s]\n",
      "100%|██████████████████████████████████████| 5095/5095 [00:05<00:00, 895.28it/s]\n",
      "100%|██████████████████████████████████████| 5095/5095 [00:08<00:00, 632.96it/s]\n",
      "100%|██████████████████████████████████████| 5095/5095 [00:09<00:00, 513.62it/s]\n",
      "100%|██████████████████████████████████████| 5096/5096 [00:12<00:00, 414.91it/s]\n",
      "100%|██████████████████████████████████████| 5094/5094 [00:15<00:00, 335.97it/s]\n",
      "100%|██████████████████████████████████████| 5095/5095 [00:18<00:00, 273.62it/s]\n",
      "100%|██████████████████████████████████████| 5095/5095 [00:22<00:00, 227.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4462/4462 [00:00<00:00, 5092.78it/s]\n",
      "100%|█████████████████████████████████████| 4509/4509 [00:01<00:00, 3277.18it/s]\n",
      "100%|█████████████████████████████████████| 4415/4415 [00:02<00:00, 2153.40it/s]\n",
      "100%|█████████████████████████████████████| 4463/4463 [00:03<00:00, 1394.04it/s]\n",
      "100%|██████████████████████████████████████| 4461/4461 [00:04<00:00, 992.94it/s]\n",
      "100%|██████████████████████████████████████| 4461/4461 [00:06<00:00, 726.64it/s]\n",
      "100%|██████████████████████████████████████| 4462/4462 [00:08<00:00, 536.93it/s]\n",
      "100%|██████████████████████████████████████| 4462/4462 [00:10<00:00, 423.27it/s]\n",
      "100%|██████████████████████████████████████| 4462/4462 [00:13<00:00, 339.58it/s]\n",
      "100%|██████████████████████████████████████| 4462/4462 [00:15<00:00, 281.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3114/3114 [00:00<00:00, 8327.09it/s]\n",
      "/Users/corey/uzh/HS21/network/venv/lib/python3.8/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "100%|█████████████████████████████████████| 2779/2779 [00:00<00:00, 4584.02it/s]\n",
      "/Users/corey/uzh/HS21/network/venv/lib/python3.8/site-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "100%|█████████████████████████████████████| 2845/2845 [00:01<00:00, 2718.59it/s]\n",
      "100%|█████████████████████████████████████| 2910/2910 [00:01<00:00, 1463.33it/s]\n",
      "100%|██████████████████████████████████████| 2912/2912 [00:03<00:00, 925.26it/s]\n",
      "100%|██████████████████████████████████████| 2912/2912 [00:04<00:00, 702.30it/s]\n",
      "100%|██████████████████████████████████████| 2913/2913 [00:05<00:00, 582.52it/s]\n",
      "100%|██████████████████████████████████████| 2911/2911 [00:05<00:00, 501.95it/s]\n",
      "100%|██████████████████████████████████████| 2913/2913 [00:06<00:00, 428.15it/s]\n",
      "100%|██████████████████████████████████████| 2911/2911 [00:07<00:00, 364.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1519/1519 [00:00<00:00, 11662.00it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:00<00:00, 7398.75it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:00<00:00, 5186.26it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:00<00:00, 3768.04it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:00<00:00, 2618.12it/s]\n",
      "100%|█████████████████████████████████████| 1518/1518 [00:00<00:00, 1783.36it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:01<00:00, 1406.97it/s]\n",
      "100%|█████████████████████████████████████| 1519/1519 [00:01<00:00, 1128.58it/s]\n",
      "100%|██████████████████████████████████████| 1519/1519 [00:01<00:00, 960.56it/s]\n",
      "100%|██████████████████████████████████████| 1519/1519 [00:01<00:00, 825.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6066/6066 [00:00<00:00, 7020.01it/s]\n",
      "100%|█████████████████████████████████████| 6066/6066 [00:02<00:00, 2453.30it/s]\n",
      "100%|█████████████████████████████████████| 6066/6066 [00:05<00:00, 1156.60it/s]\n",
      "100%|██████████████████████████████████████| 6065/6065 [00:07<00:00, 824.97it/s]\n",
      "100%|██████████████████████████████████████| 6066/6066 [00:08<00:00, 688.49it/s]\n",
      "100%|██████████████████████████████████████| 6066/6066 [00:10<00:00, 557.98it/s]\n",
      "100%|██████████████████████████████████████| 6067/6067 [00:12<00:00, 480.53it/s]\n",
      "100%|██████████████████████████████████████| 6064/6064 [00:15<00:00, 379.88it/s]\n",
      "100%|██████████████████████████████████████| 6066/6066 [00:16<00:00, 372.87it/s]\n",
      "100%|██████████████████████████████████████| 6066/6066 [00:19<00:00, 310.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4658/4658 [00:01<00:00, 2985.24it/s]\n",
      "100%|█████████████████████████████████████| 4711/4711 [00:03<00:00, 1237.61it/s]\n",
      "100%|██████████████████████████████████████| 4584/4584 [00:06<00:00, 725.31it/s]\n",
      "100%|██████████████████████████████████████| 4646/4646 [00:09<00:00, 475.67it/s]\n",
      "100%|██████████████████████████████████████| 4650/4650 [00:13<00:00, 353.03it/s]\n",
      "100%|██████████████████████████████████████| 4649/4649 [00:16<00:00, 282.57it/s]\n",
      "100%|██████████████████████████████████████| 4650/4650 [00:20<00:00, 230.28it/s]\n",
      "100%|██████████████████████████████████████| 4649/4649 [00:25<00:00, 183.38it/s]\n",
      "100%|██████████████████████████████████████| 4650/4650 [00:29<00:00, 159.16it/s]\n",
      "100%|██████████████████████████████████████| 4650/4650 [00:33<00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4317/4317 [00:01<00:00, 3374.04it/s]\n",
      "100%|█████████████████████████████████████| 4313/4313 [00:03<00:00, 1432.51it/s]\n",
      "100%|█████████████████████████████████████| 4316/4316 [00:04<00:00, 1014.85it/s]\n",
      "100%|██████████████████████████████████████| 4299/4299 [00:05<00:00, 775.81it/s]\n",
      "100%|██████████████████████████████████████| 4311/4311 [00:06<00:00, 661.32it/s]\n",
      "100%|██████████████████████████████████████| 4311/4311 [00:07<00:00, 589.44it/s]\n",
      "100%|██████████████████████████████████████| 4311/4311 [00:08<00:00, 508.06it/s]\n",
      "100%|██████████████████████████████████████| 4315/4315 [00:10<00:00, 429.39it/s]\n",
      "100%|██████████████████████████████████████| 4307/4307 [00:11<00:00, 359.15it/s]\n",
      "100%|██████████████████████████████████████| 4312/4312 [00:14<00:00, 302.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2302/2302 [00:00<00:00, 3837.06it/s]\n",
      "100%|█████████████████████████████████████| 2181/2181 [00:01<00:00, 1480.96it/s]\n",
      "100%|██████████████████████████████████████| 2205/2205 [00:02<00:00, 920.94it/s]\n",
      "100%|██████████████████████████████████████| 2235/2235 [00:03<00:00, 656.58it/s]\n",
      "100%|██████████████████████████████████████| 2213/2213 [00:04<00:00, 528.60it/s]\n",
      "100%|██████████████████████████████████████| 2221/2221 [00:05<00:00, 441.30it/s]\n",
      "100%|██████████████████████████████████████| 2226/2226 [00:05<00:00, 374.68it/s]\n",
      "100%|██████████████████████████████████████| 2226/2226 [00:06<00:00, 335.95it/s]\n",
      "100%|██████████████████████████████████████| 2291/2291 [00:07<00:00, 306.90it/s]\n",
      "100%|██████████████████████████████████████| 2162/2162 [00:08<00:00, 240.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3420/3420 [00:01<00:00, 3291.11it/s]\n",
      "100%|█████████████████████████████████████| 3438/3438 [00:02<00:00, 1298.61it/s]\n",
      "100%|██████████████████████████████████████| 3362/3362 [00:04<00:00, 788.56it/s]\n",
      "100%|██████████████████████████████████████| 3397/3397 [00:05<00:00, 572.88it/s]\n",
      "100%|██████████████████████████████████████| 3405/3405 [00:07<00:00, 463.05it/s]\n",
      "100%|██████████████████████████████████████| 3404/3404 [00:08<00:00, 391.41it/s]\n",
      "100%|██████████████████████████████████████| 3404/3404 [00:10<00:00, 320.43it/s]\n",
      "100%|██████████████████████████████████████| 3405/3405 [00:10<00:00, 310.90it/s]\n",
      "100%|██████████████████████████████████████| 3403/3403 [00:10<00:00, 317.81it/s]\n",
      "100%|██████████████████████████████████████| 3405/3405 [00:11<00:00, 286.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n",
      "Successfully wrote snapshot\n"
     ]
    }
   ],
   "source": [
    "for project in projects:\n",
    "    column_names = [\n",
    "        \"date\", \n",
    "        \"days_since_mint\", \n",
    "        \"from_address\", \n",
    "        \"to_address\", \n",
    "        \"token_id\", \n",
    "        \"blk_number\", \n",
    "        \"eth_value\",\n",
    "        \"usd_value\",\n",
    "        \"from_value\", \n",
    "        \"to_value\",\n",
    "        \"from_value_usd\",\n",
    "        \"to_value_usd\"\n",
    "    ]\n",
    "    \n",
    "    np_data = np.load(f\"./memory/{project}/full.npy\", allow_pickle=True)\n",
    "    df_time = pd.DataFrame(data=np_data, columns=column_names)\n",
    "    \n",
    "    df_snapshot_summary, g_snapshots = build_snapshots(df_time)\n",
    "    \n",
    "    for i, snapshot in enumerate(g_snapshots):\n",
    "        nx.write_gml(snapshot, f\"./memory/{project}/snapshots/{i}.gml\")\n",
    "        print(\"Successfully wrote snapshot\")\n",
    "    \n",
    "    np.save(f\"./memory/{project}/snapshots/summary.npy\", df_snapshot_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781e018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
